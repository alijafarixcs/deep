{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('IRIS.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['species'] = le.fit_transform(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self, n_input,n_neuron):\n",
    "        self.weights_bias = np.random.randn(n_input+1,n_neuron) *0.1\n",
    "        #last row is bias\n",
    "    def  forward(self,input_row):\n",
    "        self.output_row=np.dot(input_row,self.weights_bias[:-1])+self.weights_bias[-1]\n",
    "        \n",
    "    def ReLu(self):\n",
    "        self.output_row_ReLu=np.maximum(0,self.output_row)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SoftMax:\n",
    "    def __init__(self, input):\n",
    "        self.input=input\n",
    "    def doSoftmax(self):\n",
    "        self.exps=np.exp(self.input-np.max(self.input,axis=1,keepdims=True))\n",
    "        self.soft=self.exps/np.sum(self.exps,axis=1,keepdims=True)\n",
    "        self.arg_soft=np.argmax(self.soft,axis=1)\n",
    "        \n",
    "\n",
    "    def Loss(self,target:np.array):\n",
    "        self.loss=0\n",
    "        for i,val in enumerate(self.soft):\n",
    "            self.loss+=target[i]*np.log(val[target[i]])\n",
    "        self.loss*=-1\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:4]\n",
    "y=df.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 2, 0]), array([1, 1, 1, 1], dtype=int64), 5.620028931587577)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand=df.sample(4)\n",
    "X_sample=np.array(rand.iloc[:,:4])\n",
    "y_sample=np.array(rand.iloc[:,4])\n",
    "\n",
    "\n",
    "dense1=Dense_Layer(4,9)\n",
    "dense2=Dense_Layer(9,6)\n",
    "dense3=Dense_Layer(6,3)\n",
    "\n",
    "\n",
    "dense1.forward(X_sample)\n",
    "dense1.ReLu()\n",
    "dense2.forward(dense1.output_row)\n",
    "dense2.ReLu()\n",
    "dense3.forward(dense2.output_row)\n",
    "soft=SoftMax(dense3.output_row)\n",
    "soft.doSoftmax()\n",
    "soft.Loss(y_sample)\n",
    "\n",
    "y_sample,soft.arg_soft,soft.loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
